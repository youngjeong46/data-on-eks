"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[9955],{3905:(e,o,t)=>{t.d(o,{Zo:()=>m,kt:()=>h});var n=t(7294);function r(e,o,t){return o in e?Object.defineProperty(e,o,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[o]=t,e}function a(e,o){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);o&&(n=n.filter((function(o){return Object.getOwnPropertyDescriptor(e,o).enumerable}))),t.push.apply(t,n)}return t}function s(e){for(var o=1;o<arguments.length;o++){var t=null!=arguments[o]?arguments[o]:{};o%2?a(Object(t),!0).forEach((function(o){r(e,o,t[o])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(o){Object.defineProperty(e,o,Object.getOwnPropertyDescriptor(t,o))}))}return e}function i(e,o){if(null==e)return{};var t,n,r=function(e,o){if(null==e)return{};var t,n,r={},a=Object.keys(e);for(n=0;n<a.length;n++)t=a[n],o.indexOf(t)>=0||(r[t]=e[t]);return r}(e,o);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)t=a[n],o.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var c=n.createContext({}),p=function(e){var o=n.useContext(c),t=o;return e&&(t="function"==typeof e?e(o):s(s({},o),e)),t},m=function(e){var o=p(e.components);return n.createElement(c.Provider,{value:o},e.children)},u="mdxType",l={inlineCode:"code",wrapper:function(e){var o=e.children;return n.createElement(n.Fragment,{},o)}},d=n.forwardRef((function(e,o){var t=e.components,r=e.mdxType,a=e.originalType,c=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),u=p(t),d=r,h=u["".concat(c,".").concat(d)]||u[d]||l[d]||a;return t?n.createElement(h,s(s({ref:o},m),{},{components:t})):n.createElement(h,s({ref:o},m))}));function h(e,o){var t=arguments,r=o&&o.mdxType;if("string"==typeof e||r){var a=t.length,s=new Array(a);s[0]=d;var i={};for(var c in o)hasOwnProperty.call(o,c)&&(i[c]=o[c]);i.originalType=e,i[u]="string"==typeof e?e:r,s[1]=i;for(var p=2;p<a;p++)s[p]=t[p];return n.createElement.apply(null,s)}return n.createElement.apply(null,t)}d.displayName="MDXCreateElement"},5102:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>c,contentTitle:()=>s,default:()=>l,frontMatter:()=>a,metadata:()=>i,toc:()=>p});var n=t(7462),r=(t(7294),t(3905));const a={sidebar_position:1,sidebar_label:"EMR on EKS with Spark"},s="Amazon EMR on Amazon EKS provides up to 61% lower costs and up to 68% performance improvement for Spark workloads",i={unversionedId:"benchmarks/emr-on-eks",id:"benchmarks/emr-on-eks",title:"Amazon EMR on Amazon EKS provides up to 61% lower costs and up to 68% performance improvement for Spark workloads",description:"Amazon EMR on Amazon EKS is a deployment option offered by Amazon EMR that enables you to run Apache Spark applications on Amazon Elastic Kubernetes Service (Amazon EKS) in a cost-effective manner. It uses the EMR runtime for Apache Spark to increase performance so that your jobs run faster and cost less.",source:"@site/docs/benchmarks/emr-on-eks.md",sourceDirName:"benchmarks",slug:"/benchmarks/emr-on-eks",permalink:"/data-on-eks/docs/benchmarks/emr-on-eks",draft:!1,editUrl:"https://github.com/awslabs/data-on-eks/blob/main/website/docs/benchmarks/emr-on-eks.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,sidebar_label:"EMR on EKS with Spark"},sidebar:"benchmarks"},c={},p=[{value:"How does Amazon EMR on EKS reduce cost and improve performance?",id:"how-does-amazon-emr-on-eks-reduce-cost-and-improve-performance",level:2},{value:"Benchmarking",id:"benchmarking",level:2}],m={toc:p},u="wrapper";function l(e){let{components:o,...a}=e;return(0,r.kt)(u,(0,n.Z)({},m,a,{components:o,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"amazon-emr-on-amazon-eks-provides-up-to-61-lower-costs-and-up-to-68-performance-improvement-for-spark-workloads"},"Amazon EMR on Amazon EKS provides up to 61% lower costs and up to 68% performance improvement for Spark workloads"),(0,r.kt)("p",null,"Amazon EMR on Amazon EKS is a deployment option offered by Amazon EMR that enables you to run Apache Spark applications on Amazon Elastic Kubernetes Service (Amazon EKS) in a cost-effective manner. It uses the EMR runtime for Apache Spark to increase performance so that your jobs run faster and cost less."),(0,r.kt)("p",null,"In our benchmark tests using TPC-DS datasets at 3 TB scale, we observed that Amazon EMR on EKS provides up to 61% lower costs and up to 68% improved performance compared to running open-source Apache Spark on Amazon EKS via equivalent configurations. In this post, we walk through the performance test process, share the results, and discuss how to reproduce the benchmark. We also share a few techniques to optimize job performance that could lead to further cost-optimization for your Spark workloads."),(0,r.kt)("h2",{id:"how-does-amazon-emr-on-eks-reduce-cost-and-improve-performance"},"How does Amazon EMR on EKS reduce cost and improve performance?"),(0,r.kt)("p",null,"The EMR runtime for Spark is a performance-optimized runtime for Apache Spark that is 100% API compatible with open-source Apache Spark. It\u2019s enabled by default with Amazon EMR on EKS. It helps run Spark workloads faster, leading to lower running costs. It includes multiple performance optimization features, such as Adaptive Query Execution (AQE), dynamic partition pruning, flattening scalar subqueries, bloom filter join, and more."),(0,r.kt)("p",null,"In addition to the cost benefit brought by the EMR runtime for Spark, Amazon EMR on EKS can take advantage of other AWS features to further optimize cost. For example, you can run Amazon EMR on EKS jobs on Amazon Elastic Compute Cloud (Amazon EC2) Spot Instances, providing up to 90% cost savings when compared to On-Demand Instances. Also, Amazon EMR on EKS supports Arm-based Graviton EC2 instances, which creates a 15% performance improvement and up to 30% cost savings when compared a Graviton2-based M6g to M5 instance type."),(0,r.kt)("p",null,"The recent graceful executor decommissioning feature makes Amazon EMR on EKS workloads more robust by enabling Spark to anticipate Spot Instance interruptions. Without the need to recompute or rerun impacted Spark jobs, Amazon EMR on EKS can further reduce job costs via critical stability and performance improvements."),(0,r.kt)("p",null,"Additionally, through container technology, Amazon EMR on EKS offers more options to debug and monitor Spark jobs. For example, you can choose Spark History Server, Amazon CloudWatch, or Amazon Managed Prometheus and Amazon Managed Grafana (for more details, refer to the Monitoring and Logging workshop). Optionally, you can use familiar command line tools such as kubectl to interact with a job processing environment and observe Spark jobs in real time, which provides a fail-fast and productive development experience."),(0,r.kt)("p",null,"Amazon EMR on EKS supports multi-tenant needs and offers application-level security control via a job execution role. It enables seamless integrations to other AWS native services without a key-pair set up in Amazon EKS. The simplified security design can reduce your engineering overhead and lower the risk of data breach. Furthermore, Amazon EMR on EKS handles security and performance patches so you can focus on building your applications."),(0,r.kt)("h2",{id:"benchmarking"},"Benchmarking"),(0,r.kt)("p",null,"This post provides an end-to-end Spark benchmark solution so you can get hands-on with the performance test process. The solution uses unmodified TPC-DS data schema and table relationships, but derives queries from TPC-DS to support the Spark SQL test case. It is not comparable to other published TPC-DS benchmark results."),(0,r.kt)("p",null,"Key concepts\nTransaction Processing Performance Council-Decision Support (TPC-DS) is a decision support benchmark that is used to evaluate the analytical performance of big data technologies. Our test data is a TPC-DS compliant dataset based on the TPC-DS Standard Specification, Revision 2.4 document, which outlines the business model and data schema, relationship, and more. As the whitepaper illustrates, the test data contains 7 fact tables and 17 dimension tables, with an average of 18 columns. The schema consists of essential retailer business information, such as customer, order, and item data for the classic sales channels: store, catalog, and internet. This source data is designed to represent real-world business scenarios with common data skews, such as seasonal sales and frequent names. Additionally, the TPC-DS benchmark offers a set of discrete scaling points (scale factors) based on the approximate size of the raw data. In our test, we chose the 3 TB scale factor, which produces 17.7 billion records, approximately 924 GB compressed data in Parquet file format."),(0,r.kt)("p",null,"Test approach\nA single test session consists of 104 Spark SQL queries that were run sequentially. To get a fair comparison, each session of different deployment types, such as Amazon EMR on EKS, was run three times. The average runtime per query from these three iterations is what we analyze and discuss in this post. Most importantly, it derives two summarized metrics to represent our Spark performance:"),(0,r.kt)("p",null,"Total execution time \u2013 The sum of the average runtime from three iterations\nGeomean \u2013 The geometric mean of the average runtime\nTest results\nIn the test result summary (see the following figure), we discovered that the Amazon EMR-optimized Spark runtime used by Amazon EMR on EKS is approximately 2.1 times better than the open-source Spark on Amazon EKS in geometric mean and 3.5 times faster by the total runtime."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"img1.png",src:t(5205).Z,width:"500",height:"385"})),(0,r.kt)("p",null,"The following figure breaks down the performance summary by queries. We observed that EMR runtime for Spark was faster in every query compared to open-source Spark. Query q67 was the longest query in the performance test. The average runtime with open-source Spark was 1019.09 seconds. However, it took 150.02 seconds with Amazon EMR on EKS, which is 6.8 times faster. The highest performance gain in these long-running queries was q72\u2014319.70 seconds (open-source Spark) vs. 26.86 seconds (Amazon EMR on EKS), a 11.9 times improvement."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"img2.png",src:t(6737).Z,width:"1780",height:"852"})),(0,r.kt)("p",null,"For full ",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/blogs/big-data/amazon-emr-on-amazon-eks-provides-up-to-61-lower-costs-and-up-to-68-performance-improvement-for-spark-workloads/"},"blog link")))}l.isMDXComponent=!0},5205:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/img1-766a1160d34ca8a7bff627a87be0c16b.png"},6737:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/img2-f53abb97b193f5428d846d0c9e98fa1d.png"}}]);